input {
  jdbc {
    jdbc_driver_library => "c:\dev\jdbc_driver_library\sqljdbc_4.2\enu\sqljdbc42.jar"
    jdbc_driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
    jdbc_connection_string => "jdbc:sqlserver://192.168.192.150;"
    jdbc_user => "GISViews"
    jdbc_password => "%Gs123"
    ##jdbc_password_filepath => "C:\Apache24\htdocs\EPASearch\logstash_settings\pass\passgis.txt"
    jdbc_fetch_size => 100
    use_column_value => true
    tracking_column_type => timestamp
    tracking_column => raw_reading_measurement_time
    record_last_run => true
    last_run_metadata_path => "C:\Apache24\htdocs\EPASearch\logstash_settings\last_run\aq\aq_all_measurements_out_mongodb\.logstash_jdbc_last_run"
    schedule => "*/5 * * * *"
    #schedule => "* * * * *"
    ##schedule => "50 2,15,16,22 * * *"
    statement_filepath => "C:\Apache24\htdocs\EPASearch\logstash_settings\sql\aq\aq_all_measurements_mongodb.sql"
  }
}

#filter {
#  mutate {
#    add_field => ["logstash_checksum", "%{rawreadingid}"]
#  }
#  anonymize {
#    fields => ["logstash_checksum"]
#    algorithm => "MD5"
#    key => "a"
#  }
#  #ruby {
#    #event['computed_id'] = 'rawreadingid';
#    #code => "
#    #hash = event.to_hash
#      #hash.each do |k,v|
#      #  if v == nil
#      #    event.remove(k)
#      #  end
#      #end
 #   #"
#  #}
#}

output {
  mongodb {
    #uri => "mongodb://[developeruser:MMEPATest1!@]127.0.0.1:27017"
    uri => "mongodb://127.0.0.1:27017"
    database => "aq"
    collection => "aq_measurements"
    id => "mongo_logstash_001"
    isodate => true
    #codec => "json"
    #generateId => true
    #_id => "%{rawreadingid}"
    #document_id => "%{rawreadingid}"
  }
#  elasticsearch {
#    hosts => ["localhost:9214"]
#    index => "aq"
#    document_type => "aq_measurements"
#	document_id => '%{rawreadingid}'
#  }

  stdout { codec => rubydebug }
}